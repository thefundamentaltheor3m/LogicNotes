\section{Subalgebras of $\gl{n}$}

We now turn our attention to the structure of subalgebras of $\gl{n}$ for some fixed $n \in \N$. We will begin by developing some mroe general theory, following which we will prove important theorems about the structure of such subalgebras.

\subsection{Induced Actions on Quotients by Invariant Subspaces}
\label{Ch1:Subsec:QuotientByInvariantSubspaces}

We will begin by recalling the linear algebraic theory of invariant subspaces and adapt that theory to the context of Lie algebras. Throughout this subsection, we will fix a subset $L \subseteq \gl{n}$ and a subspace $U \leq \C^n$.

\begin{definition}[Invariance]
    We say that $U$ is \textbf{$L$-invariant} if for all $T \in L$ and $v \in U$, we have $\Tv \in U$.
\end{definition}

The action of $L$ on $\C^n$ induces a natural action on the quotient space of $\C^n$ by $U$.

\begin{definition}[Induced Action]
    To each $T \in L$, we can associate the linear map $\Tbar : \quotient{\C^n}{U} \to \quotient{\C^n}{U}$ defined by
    \begin{align}
        \Tbar(v + U) = \Tv + U
    \end{align}
    for all $v + U \in \quotient{\C^n}{U}$. We will refer to the map $T \mapsto \Tbar$ as the \textbf{induced action} of $L$ on $\quotient{\C^n}{U}$.
\end{definition}

Indeed, when $L$ is a Lie subalgebra of $\gl{n}$, we can go one step further.

\begin{boxproposition}\label{Ch1:Prop:InducedActionLieAlg}
    If $L$ is a Lie subalgebra of $\gl{n}$, the induced action map $\Phi : L \to \gl{\quotient{\C^n}{U}} : T \mapsto \Tbar$ is a Lie algebra homomorphism.
\end{boxproposition}
\begin{proof}
    \sorry
    % The idea is to show it to be a homomorphism of associative algebras instead.
\end{proof}

\subsection{Linear Algebraic and Lie Algebraic Nilpotency}

Recall the following definition from linear algebra.

\begin{boxdefinition}[Nilpotency of Elements]
    We say that $x \in \gl{n}$ is \textbf{nilpotent} if there exists an $m \in \N$ such that $x^m = 0$. 
\end{boxdefinition}

We can extend this to sub-vector spaces.

\begin{boxdefinition}[Nilpotency of Subspaces]
    We say a sub-vector space $N \leq \gl{n}$ is \textbf{nilpotent} if every element of $N$ is nilpotent.
\end{boxdefinition}

We can say something about the adjoint of a nilpotent element.

\begin{lemma}\label{Ch1:Lemma:adNilpotnetOfNilpotent}
    Let $x \in \gl{n}$ be nilpotent. Then, $\pad{x} \in \gl{\gl{n}}$ is nilpotent as well.
\end{lemma}
\begin{proof}
    We need to show that there exists an $m \in \N$ such that the map we get by successively composing the adjoint map $\pad{x}$ $m$ times is identically zero.
    
    Fix $y \in \gl{n}$. Then,
    \begin{align*}
        \pad{x}\!(y) = \brac{x, y} &= xy - yx \\
        \pad{x}^2\!(y) = \brac{x, \brac{x, y}} &= x\brac{x, y} - \brac{x, y}x = x^2y - xyx - xyx + yx^2 \\
        \pad{x}^3\!(y) = \brac{x, \brac{x, \brac{x, y}}} &= x^3y + \cdots + xyx^2 - yx^3
    \end{align*}
    More generally, one can show that
    \begin{align*}
        \pad{x}^m\!(y) = \sum_{i = 0}^{m} \lambda_{i, m} x^i y x^{m - i}
    \end{align*}
    for all $m \in \N$ and some $\lambda_{i, m} \in \Z$. In particular, since all powers of $x$ beyond some $m$ are zero, we have that $\pad{x}^m\!(y) = 0$ for all $y \in \gl{n}$.
\end{proof}

We have an important relationship between linear algebraic and lie algebraic nilpotency of a Lie subalgebra.

\begin{boxtheorem}[Engel's Theorem]\label{Ch1:Thm:Engel}
    Let $N$ be a Lie subalgebra of $\gl{n}$. If $N$ is nilpotent as a sub-vector space of $\gl{n}$, then there exists a basis of $\C^n$ with respect to which every element of $N$ is upper-triangular.
\end{boxtheorem}

Before proving Engel's Theorem, we will state and prove the following Corollary that underscores the significance of this result.

\begin{boxcorollary}\label{Ch1:Cor:EngelNilpotency}
    Any nilpotent sub-vector space of $\gl{n}$ is also nilpotent as a Lie subalgebra.
\end{boxcorollary}
\begin{proof}
    Let $N$ be a nilpotent sub-vector space of $\gl{n}$. By Engel's Theorem, there exists a basis of $\C^n$ with respect to which every element of $N$ is upper-triangular. In particular, they must all have zeros on the diagonal, because they are nilpotent: they are of the form
    \begin{align*}
        \begin{bmatrix}
            0 & & * \\
            \vdots & \ddots & \\
            0 & \cdots & 0
        \end{bmatrix}
    \end{align*}
    \sorry
\end{proof}

For the remainder of this subsection, we will focus on proving Engel's Theorem. We will fix a nilpotent subspace $N \leq \gl{n}$. The high-level idea is to perform induction on $\pdim{L}$ and draw a parallel with the proof of the Jordan Canonical Form theorem\footnote{Remember, we are working over $\C$.}. We will first show that it suffices to show that a certain distinguished vector exists, following which we will show that it does.

For the remainder of this subsection, we will denote the \textbf{simultaneous kernel} of all elements of $N$ by
\begin{align}
    U_n := \setst{v \in \C^n}{\forall T \in N, \ \Tv = 0} = \bigcap_{T \in N} \pker{T}
    \label{Ch1:Eq:Simultaneous_Kernel_Def}
\end{align}
As an intersection of sub-vector spaces, $U_n$ is a subspace of $\C^n$. Furthermore, $U_n$ (and, by extension, all of its subspaces) are $N$-invariant: for all $T \in N$ and $v \in U_n$, we have $\Tv = 0 \in U_n$.

We are now ready to reduce the proof of Engel's Theorem to showing that all the elements of $T$ have a common eigenvector with eigenvalue $0$---or, equivalently, to showing that $U_n$ is nonzero.

\begin{lemma}
    If $U_n$ contains a nonzero element, then there exists a basis of $\C^n$ with respect to which every element of $N$ is upper-triangular.
\end{lemma}
\begin{proof}
    We argue by induction on $n$. When $n = 1$, the result is trivial: every element of $N$ (and of $\gl{n} = \gl{1}$) is upper-triangular, so the fact that $U_n = 0$ is not a problem. Now, suppose that there exists a nonzero element $v \in U_n$, ie, such that $\Tv = 0$ for all $T \in N$. Let $V = \quotient{\C^n}{\Span{v}}$. Since $\Span{v} \leq U_n$ and $U_n$ is $N$-invariant, we know that $\Span{v}$ is $N$-invariant as well, allowing us to develop the machinery developed in \Cref{Ch1:Subsec:QuotientByInvariantSubspaces} that tells us about the Lie algebraic properties of $\gl{V}$.
    
    From \Cref{Ch1:Prop:InducedActionLieAlg}, we know that the map that takes $T \in N$ to its induced action on $V$ is a Lie algebra homomorphism. Therefore, by \Cref{Ch1:Lemma:im_ker_subalg}, its image is a subalgebra of $\gl{V}$. Indeed, the elements of this subalgebra consists of nilpotent elements: for any $T \in \gl{V}$, we know there exists some $m \in \N$ such that $T^m = 0$, and the same $m$ will work for the induced action $\Tbar$ of $T$ on the quotient space: for any $x + \Span{v} \in \quotient{\C^n}{\Span{v}}$,
    \begin{align*}
        \overline{T}^m(x + U) = \overline{T}^m(x) + U = 0 + U
    \end{align*}
    Therefore, by the induction hypothesis, there exists a basis
    \begin{align*}
        \overline{B} := \set{v_1 + \Span{v}, \ldots, v_{n - 1} + \Span{v}}
    \end{align*}
    of $V$ with respect to which every element of the image of $N$ is upper-triangular. We can then lift this basis to a basis and this basis
    \begin{align*}
        B := \set{v_1, \ldots, v_{n - 1}, v}
    \end{align*}
    of $\C^n$ by adding $v$ to it. $B$ has the desired property that every element of $N$ is upper-triangular with respect to it.
\end{proof}

% What exactly does this mean? Put it elsewhere perhaps...

The way we will prove Engel's Theorem is to construct a sequence of subspaces
\begin{align*}
    0 = V_0 \subsetneq V_1 \subsetneq \cdots \subsetneq V_m = \C^n
\end{align*}
such that $N(V_i) \subseteq V_{i - 1}$. We will refine this sequence so that $m = n$, ie, so that
\begin{align*}
    \pdim{\quotient{V_{i}}{V_{i - 1}}} = 1
\end{align*}
using \Cref{Ch1:Prop:ExistsIdealCodim1}. We can then take distinguished elements from each of the quotients to form a basis of $\C^n$, and this will be the basis with respect to which every element of $N$ is upper-triangular.

We will now show that $U_n$ is, indeed, nonzero.

\begin{lemma}
    There exists a nonzero vector $v \in U_n$.
\end{lemma}
\begin{proof}
    We need to show that $\Tv = 0$ for all $T \in N$. We argue by induction on $\pdim{N}$. The base case $\pdim{N} = 1$ is clear: $N$ must be the span of a single, nilpotent element, which necessarily has a (nonzero) eigenvector with eigenvalue $0$. So, assume $N$ is such that for all Lie subalgebras of $\gl{n}$ of dimension less than $\pdim{N}$, there exists a nonzero vector in the simultaneous kernel $U_n$ of all elements of $N$.
    
    Let $A \subseteq N$ be a maximal\footnote{with respect to inclusion}, proper Lie subalgebra of $N$. Consider the map $\phi : A \to \gl{\quotient{N}{A}}$ that maps any $g \in A$ to the map that sends every $T + A \in \quotient{N}{A}$ to the map $\brac{g, T} + A \in \quotient{N}{A}$, where the map $\brac{g, T}$ is the map $gT - Tg$. % Something like the induced action of the adjoint map??? That would immediately give us all the machinery defined in the section about quotienting by invariant subalgebras.

    Observe that since $\pdim{\phiof{A}} \leq \pdim{A}$ and $\pdim{A} < \pdim{L}$ by the assumption that $A$ is proper, we know that $\pdim{A} < L$. Therefore,we can apply the induction hypothesis to $A$.
    \sorry
\end{proof}

% IDEA: Begin by taking a nonzero element of the overarching Lie algebra N. We know that its bracket with itself is zero. Its span is a subalgebra because any 1D subspace is a subalgebra. We need other guys such that their brackets with the first guy are contained in their span. This is how we build the basis we need.

There is also a more general formulation of Engel's Theorem over arbitrary Lie algebras.

\begin{boxtheorem}[Engel's Theorem, Second Version]\label{Ch1:Thm:EngelOverAnyLie}
    Let $L$ be an arbitrary Lie algebra. Then, $L$ is nilpotent if and only if for all $x \in L$, the adjoint map $\pad{x}$ is nilpotent.
\end{boxtheorem}
\begin{proof}
    Assume that $L$ is nilpotent. Then, there exists some $m \in \N$ such that $L^m = 0$. Then, any composition of Lie brackets of length $m$ is zero: for all $x, y \in L$,
    \begin{align*}
        \pad{x}^n\!(y) = \brac{x, \brac{x, \cdots \brac{x, y}\cdots}} = 0
    \end{align*}
    This gives us one direction of the proof.

    For the converse direction, we apply \Cref{Ch1:Thm:Engel} (the standard formulation of Engel's Theorem) to the \sorry
\end{proof}

\subsection{Weights of Lie Algebras}

Throughout this subsection, let $V$ be a finite-dimensional $\C$-vector space, $L$ a lie subalgebra of $\gl{V}$, and $\lambda : L \to \C$ be an arbitrary function.

\begin{boxdefinition}[Weight Space]
    We say the \textbf{weight space} of $\lambda$ with respect to $L$ %?%
    is the space
    \begin{align*}
        V_{\lambda} := \setst{v \in V}{\forall T \in L, \ \Tv = \lambda(T) \cdot v}
    \end{align*}
\end{boxdefinition}

The weight space gives us useful information about $L$ and $\lambda$.

\begin{lemma}
    If $V_{\lambda}$ is nonzero, then $\lambda$ is a linear map.
\end{lemma}
\begin{proof}
    Suppose that $V_{\lambda} \neq 0$. Fix $S, T \in L$. We know there exists a nonzero vector $v \in V$ such that $\Sof{v} = \lambda(S) \cdot v$ and $\Tv = \lambda(T) \cdot v$. In particular, we have that
    \begin{align*}
        \lambda(S + T) \cdot v = (S + T)(v) = \Sof{v} + \Tof{v} = \lambda(S) \cdot v + \lambda(T) \cdot v = (\lambda(S) + \lambda(T)) \cdot v
    \end{align*}
    Given that $\lambda(S + T)$ and $\lambda(S) + \lambda(T)$ are both scalars, we must have that $\lambda(S + T) = \lambda(S) + \lambda(T)$.
\end{proof}

\begin{lemma}
    $V_\lambda$ is a sub-vector space of $V$.
\end{lemma}
\begin{proof}
    \sorry
\end{proof}

Weight spaces are rather interesting, and in the remainder of this subsection, we will prove a lemma that will help us prove the very important \Cref{Ch1:Thm:Lie}, which we shall see shortly.

\begin{boxlemma}[The Invariance Lemma]\label{Ch1:Lemma:InvarianceLemma}  % cf. Lemma 5.5 in Erdmann Wildon
    Let $A$ be an ideal of $L$ and let $\lambda : A \to \C$ be a weight on $A$. Then, the weight space
    \begin{align*}
        V_{\lambda} = \setst{v \in V}{\forall a \in A,\ a(v) = \lambda(a) \cdot v}
    \end{align*}
    of $I$ is an $L$-invariant subspace of $V$.
\end{boxlemma}
\begin{comment} % We will follow the Erdmann-Wildon proof instead.
    Fix $u \in U$ and $T \in L$. Let $\mu : I \to \C$ be a map such that $U = I_{\mu}$. We want $\Tof{u}$ to be in $U$ as well: for any $S \in I$, we would like to have that
    \begin{align*}
        \Sof{\Tof{u}} = \muof{S} \cdot \Tof{u}
    \end{align*}
    First, observe that
    \begin{align*}
        \Sof{\Tof{u}}
        &= \text{\sorry} \\
        &= \brac{S, T}\!(u) + \Tof{\Sof{u}} \\
        &= \muof{\brac{S, T}} \cdot u + \Tof{\muof{S} \cdot u} \\
        &= \muof{\brac{S, T}} \cdot u + \muof{S} \cdot \Tof{u}
    \end{align*}
    If we can show that $\muof{\brac{S, T}} = 0$, we will be done.

    Consider the following subspace of $V$:
    \begin{align}
        W := \Span{\set{u, T(u), T^2(u), \ldots}}
    \end{align}
    Since $W \leq V$, which is finite-dimensional, we know $W$ is finite-dimensional as well. Then, let $m = \pdim{W}$. We know, from linear algebra, that $\setst{T^i(u)}{0 \leq i \leq m - 1}$ is a basis of $W$.
    
    We will begin by showing that for all $0 \leq i \leq m - 1$, there exist $\alpha_{i, 1}, \ldots, \alpha_{i, i - 1}$ such that
    \begin{align}
        ST^i(u) = 
        \label{Ch1:Eq:InvarianceLemma_1}
    \end{align}
    We will prove \eqref{Ch1:Eq:InvarianceLemma_1} by induction on $i$.

    \sorry

    \eqref{Ch1:Eq:InvarianceLemma_1} tells us the following two facts.
    \begin{enumerate}
        \item $W$ is $S$-invariant.
        \sorry
        \item There exists a basis of $W$ with respect to which the matrix of $S$ is
        $\displaystyle \begin{bmatrix}
            \muof{S} & & * \\
            & \ddots & \\
            0 & & \muof{S}
        \end{bmatrix}$.
        \sorry
    \end{enumerate}

    The second point above tells us that $\Tr{S} = \pdim{W} \cdot \muof{S}$. Since the above is true of all $S \in I$, it is, in particular, true of $\brac{T, S}$. % REPHRASE SO THAT WE USE A LETTER OTHER THAN S IN THE STEPS ABOVE!!!!!!!!!!
    From the fact that the trace of a commutator is zero, we know that this quantity must equal zero. We also know that $\pdim{W} \neq 0$. We can conclude that $\muof{\brac{T, S}} = 0$, as required.
    % Rephrase!!
\end{comment}
\begin{proof}
    Fix $y \in L$ and $w \in V_{\lambda}$. We want to show that $y(w) \in V_{\lambda}$, ie, that $y(w)$ is an eigenvector of every $a \in A$, with corresponding eigenvalue $\lambda(a)$.
\end{proof}

We end by computing all the weights and weight spaces of a few subalgebras of $\gl{n}$.

\begin{boxexample}
    Let $I$ denote the $n \times n$ identity matrix. Consider the set
    \begin{align*}
        \setst{\lambda \cdot I}{\lambda \in \C}
    \end{align*}
    One can show that this is a subalgebra of $\gl{n}$. In this case, there is only one weight: this is the map that sends every element $\lambda \cdot I$ of the above subalgebra to the corresponding $\lambda$. The weight space of this weight is all of $\C^n$.
\end{boxexample}

\begin{boxexample}
    Let $n = 3$, and let $E_{ij}$ denote the $3 \times 3$ matrix whose only nonzero entry is a $1$ in the $i$th row and $j$th column. Consider the set
    \begin{align*}
        \setst{
            % \lambda E_{11} + \lambda E_{22} + \mu E_{33}
            \begin{bmatrix}
                \alpha & 0 & 0 \\
                0 & \alpha & 0 \\
                0 & 0 & \beta
            \end{bmatrix}
        }{
            \alpha, \beta \in \C
        }
        % \begin{bmatrix} \lambda & 0 & 0 \\ 0 & \lambda & 0 \\ 0 & 0 & \mu \end{bmatrix}
    \end{align*}
    One can show that the above set is a subalgebra. \\

    The key to computing the weights and weight spaces is to consider the eigenvectors of the elements of the subalgebra. Clearly, a basis of the above is $\set{E_{11} + E_{22}, E_{33}}$. The two weights are the maps that send each of these to $1$. \sorry
\end{boxexample}

We can apply the above to compute the weights of the upper-triangular Lie subalgebra.

\begin{boxexample}[$\t{n}$]
    Consider the standard basis $\set{e_1, \ldots, e_n}$ of $\C^n$. We know that $\Span{e_1}$ is an eigenvector of every element of $\t{n}$. Indeed, one can show (\sorry) that it is the \textit{only} such simultaneous eigenvector. Therefore, the only weight is the one that maps any element of $\t{n}$ to the element that lives in its first row and first column, which is precisely the eigenvalue of $e_1$ under its action. \sorry
\end{boxexample}

Finally, we underscore the importance of weight spaces by mentioning that they can be used to prove a seemingly unrelated fact about matrices.

\begin{lemma}\label{Ch1:Lemma:SimulDiagOfCommuting}
    Let $A, B \in \gl{n}$ be diagonalisable. If $A$ and $B$ commute, then there exists a basis with respect to which both $A$ and $B$ are diagonalisable.
\end{lemma}
\begin{proof}
    Consider the subspace $L := \Span{A, B} \leq \gl{n}$. Observe that since $A$ and $B$ commute, $\brac{A, B} = 0$. Therefore, $L$ is an abelian Lie subalgebra of $\gl{n}$. The idea is that the weight space of 
\end{proof}

\begin{corollary}
    Let $A, B \in \gl{n}$ be diagonalisable. If $A$ and $B$ commute, then $A + B$ is diagonalisable.
\end{corollary}
\begin{proof}
    Rewrite $A$ and $B$ in the basis given in the previous lemma. Their sum is then a sum of diagonal matrices, which is diagonal (in that same basis).
\end{proof}

\subsection{Lie's Theorem}

In this subsection, we discuss a result similar to Engel's Theorem, but for \textit{solvable} Lie algebras instead of nilpotent ones. Throughout, we fix a \textbf{solvable} subalgebra $L \leq \gl{n}$ for some $n \in \N$.

\begin{boxtheorem}[Lie's Theorem]\label{Ch1:Thm:Lie}
    There exists a basis of $\C^n$ such that every element of $L$ is upper-triangular with respect to it.
\end{boxtheorem}

Before proceeding with the proof of Lie's Theorem, we will prove a corollary that underscores the significance of this result.

\begin{boxcorollary}\label{Ch1:Cor:SolvableDerivNilpotent}
    $L'$ is solvable.
\end{boxcorollary}
\begin{proof}
    Consider the adjoint map $\ad : L \to \gl{L}$. We know that $\pad{L}$ is solvable by \sorry; therefore, by Lie's Theorem, it is contained in $\t{L}$. % an object we have not quite defined...
    \sorry
\end{proof}

Our proof strategy will be to obtain some $\lambda \in L^*$, ie, a linear function $L \to \C$, such that ${\C^n}_{\lambda}$. We will repeat a simpler version of the proof of Engel's Theorem: we will perform induction on $n$, applying the induction hypothesis to the image of $L$ under the quotient epimorphism $\Phi_\lambda : L \surj \gl{\quotient{\C^n}{\C^n_\lambda}}$. $\Phi_\lambda(L)$ is solvable, because it is a quotient of a solvable Lie algebra. We will then be able to apply the fact that
\begin{align*}
    \pdim{\Phi_\lambda(L)}
    \leq \pdim{\C^n} - \pdim{\C^n_\lambda}
    < \pdim{\C^n} = n
\end{align*}
because $\C^n_{\lambda} \neq 0$, allowing us to apply the induction hypothesis on $\Phi_\lambda(L)$.

\sorry

We end with an example that shows that Lie's Theorem is not necessarily true over fields of prime characteristic.

\begin{boxcexample}[Lie's Theorem Fails over Prime Characteristic]
    Let $p$ be a prime number and let $F$ be a field of characteristic $p$. Consider the vector space $F^p$, and let $\set{e_1, \ldots, e_p}$ denote a basis of it. We know that $\gl{F^p}$, the set of $F$-linear maps from $F^p$ to itself, is a Lie algebra over $F$ with the commutator bracket. Denote it by $L$ for the purposes of this example. \\

    Consider the following elements of $L$:
    \begin{align*}
        x &:= e_i \mapsto i \cdot e_{i} \\
        y &:=
        \begin{cases}
            e_i \mapsto e_{i+1} & \text{ if } i < p \\
            e_p \mapsto e_1
        \end{cases}
         \in L
    \end{align*}
    We will show that $x$ and $y$ have no common eigenvectors, a fact we can use to generate a basis 
\end{boxcexample}

This is more of an aside, since we are primarily interested in complex Lie algebras in this module. Nevertheless, we mention it here because it is interesting.
